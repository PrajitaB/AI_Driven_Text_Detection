{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513e7c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RST x H-score METHOD\n",
    "\n",
    "# Define H-score function\n",
    "def compute_h_score(texts1, texts2):\n",
    "    \"\"\"Compute a simplified H-score (e.g., based on word frequency divergence).\"\"\"\n",
    "    def get_word_freq(texts):\n",
    "        word_count = {}\n",
    "        for text in texts:\n",
    "            words = text.lower().split()\n",
    "            for word in words:\n",
    "                word_count[word] = word_count.get(word, 0) + 1\n",
    "        total = sum(word_count.values())\n",
    "        return {k: v / total for k, v in word_count.items()}\n",
    "\n",
    "    freq1 = get_word_freq(texts1)\n",
    "    freq2 = get_word_freq(texts2)\n",
    "\n",
    "    # Hellinger distance as H-score\n",
    "    common_words = set(freq1.keys()).union(freq2.keys())\n",
    "    p = np.array([freq1.get(w, 0) for w in common_words])\n",
    "    q = np.array([freq2.get(w, 0) for w in common_words])\n",
    "    h_score = np.sqrt(np.sum((np.sqrt(p) - np.sqrt(q)) ** 2)) / np.sqrt(2)\n",
    "    return h_score\n",
    "\n",
    "# Split training data into AI and non-AI texts\n",
    "ai_texts_train = X_train[y_train == 1]\n",
    "non_ai_texts_train = X_train[y_train == 0]\n",
    "\n",
    "# Compute H-score between AI and non-AI texts\n",
    "h_score_ai_vs_non_ai = compute_h_score(ai_texts_train, non_ai_texts_train)\n",
    "print(f\"\\nH-score between AI and non-AI texts (training set): {h_score_ai_vs_non_ai:.4f}\")\n",
    "\n",
    "# Function to classify test texts using H-score threshold\n",
    "def classify_with_h_score(test_texts, ai_reference_texts, non_ai_reference_texts):\n",
    "    h_scores_ai = []\n",
    "    h_scores_non_ai = []\n",
    "    predictions = []\n",
    "\n",
    "    for text in test_texts:\n",
    "        h_score_ai = compute_h_score([text], ai_reference_texts)\n",
    "        h_score_non_ai = compute_h_score([text], non_ai_reference_texts)\n",
    "        h_scores_ai.append(h_score_ai)\n",
    "        h_scores_non_ai.append(h_score_non_ai)\n",
    "\n",
    "        # Use the difference as a confidence score (lower H-score to AI means more likely AI)\n",
    "        confidence = h_score_non_ai - h_score_ai  # Positive means more likely AI\n",
    "        predictions.append(1 if confidence > 0 else 0)\n",
    "\n",
    "    # Normalize confidence scores to [0, 1] range for ROC curve\n",
    "    confidence_scores = np.array(h_scores_non_ai) - np.array(h_scores_ai)\n",
    "    confidence_scores = (confidence_scores - confidence_scores.min()) / (confidence_scores.max() - confidence_scores.min())\n",
    "    return np.array(predictions), confidence_scores\n",
    "\n",
    "# Classify test set using H-score\n",
    "h_score_preds, h_score_probs = classify_with_h_score(X_test, ai_texts_train, non_ai_texts_train)\n",
    "print(\"\\nH-score Classification Report (threshold > 0.4 for AI):\")\n",
    "print(classification_report(y_test, h_score_preds))\n",
    "print(\"H-score Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, h_score_preds))\n",
    "\n",
    "# Plot ROC curve for H-score\n",
    "plot_roc_curve(y_test, h_score_probs, \"H-score\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
